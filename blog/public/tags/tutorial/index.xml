<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tutorial on /* Commentary */</title>
    <link>/tags/tutorial/</link>
    <description>Recent content in tutorial on /* Commentary */</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 13 Aug 2022 08:12:39 -0700</lastBuildDate><atom:link href="/tags/tutorial/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Who&#39;s the Boss?</title>
      <link>/posts/docker-swarm-managers/</link>
      <pubDate>Sat, 13 Aug 2022 08:12:39 -0700</pubDate>
      
      <guid>/posts/docker-swarm-managers/</guid>
      <description>Every node in a Docker Swarm plays at least one of two particular roles: worker and/or manager. When you create a new cluster, you start out by creating it with a single node that is both a manager and a worker, and specify an IP address to advertise that manager to other managers as you add them.
Roles So what are the responsibilities of these two roles anyway? How do you know how many managers and workers to deploy in your swarm?</description>
      <content>&lt;p&gt;Every node in a Docker Swarm plays at least one of two particular roles: worker
and/or manager. When you create a new cluster, you start out by creating it with
a single node that is both a manager and a worker, and &lt;a href=&#34;https://docs.docker.com/engine/swarm/admin_guide/#configure-the-manager-to-advertise-on-a-static-ip-address&#34;&gt;specify an IP address
to advertise that manager to other managers&lt;/a&gt; as you add them.&lt;/p&gt;
&lt;h1 id=&#34;roles&#34;&gt;Roles&lt;/h1&gt;
&lt;p&gt;So what are the responsibilities of these two roles anyway? How do you know
how many managers and workers to deploy in your swarm? Let&amp;rsquo;s get into it!&lt;/p&gt;
&lt;h2 id=&#34;managers&#34;&gt;Managers&lt;/h2&gt;
&lt;p&gt;As you might imagine, &lt;a href=&#34;https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/#manager-nodes&#34;&gt;manager nodes&lt;/a&gt; in a Docker Swarm take on
additional cluster management tasks. Such tasks include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;maintaining &amp;amp; distributing cluster state across manager nodes in the cluster&lt;/li&gt;
&lt;li&gt;scheduling services to various nodes in the swarm&lt;/li&gt;
&lt;li&gt;serving swarm mode HTTP API endpoints&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;workers&#34;&gt;Workers&lt;/h2&gt;
&lt;p&gt;Intuitively, &lt;a href=&#34;https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/#worker-nodes&#34;&gt;worker nodes&lt;/a&gt; don&amp;rsquo;t perform any of the management
tasks that the manager nodes do; all that stuff is above the pay grade.
Instead, worker nodes are solely responsible for executing service tasks.&lt;/p&gt;
&lt;h2 id=&#34;promotion--demotion&#34;&gt;Promotion &amp;amp; Demotion&lt;/h2&gt;
&lt;p&gt;Roles for nodes can be changed. To &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/node_promote/&#34;&gt;promote&lt;/a&gt; a worker node to
be a manager node, run the following:&lt;/p&gt;



  &lt;div class=&#34;collapsable-code&#34;&gt;
    &lt;input id=&#34;1&#34; type=&#34;checkbox&#34;  /&gt;
    &lt;label for=&#34;1&#34;&gt;
      &lt;span class=&#34;collapsable-code__language&#34;&gt;bash&lt;/span&gt;
      
      &lt;span class=&#34;collapsable-code__toggle&#34; data-label-expand=&#34;Show&#34; data-label-collapse=&#34;Hide&#34;&gt;&lt;/span&gt;
    &lt;/label&gt;
    &lt;pre class=&#34;language-bash&#34; &gt;&lt;code&gt;
$ docker node promote &amp;lt;NODE NAME&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;p&gt;And to &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/node_demote/&#34;&gt;demote&lt;/a&gt; a node, run this command:&lt;/p&gt;



  &lt;div class=&#34;collapsable-code&#34;&gt;
    &lt;input id=&#34;2&#34; type=&#34;checkbox&#34;  /&gt;
    &lt;label for=&#34;2&#34;&gt;
      &lt;span class=&#34;collapsable-code__language&#34;&gt;bash&lt;/span&gt;
      
      &lt;span class=&#34;collapsable-code__toggle&#34; data-label-expand=&#34;Show&#34; data-label-collapse=&#34;Hide&#34;&gt;&lt;/span&gt;
    &lt;/label&gt;
    &lt;pre class=&#34;language-bash&#34; &gt;&lt;code&gt;
$ docker node demote &amp;lt;NODE NAME&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/em&gt;: By default, all manager nodes are also worker nodes. Assuming you
have a cluster that has more than one node, you can prevent any one manager node
from taking on worker node responsibilities by moving it&amp;rsquo;s availability status
to &lt;code&gt;Drain&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;deployment-strategies&#34;&gt;Deployment Strategies&lt;/h1&gt;
&lt;p&gt;Okay, so we&amp;rsquo;ve nailed down the roles that nodes can play within a swarm, but you
may be wondering:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How do I choose which role(s) to assign to a node?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It&amp;rsquo;s a great question, and one that can have pretty large impact.&lt;/p&gt;
&lt;h2 id=&#34;to-manage-or-not-to-manage&#34;&gt;To Manage or Not to Manage&lt;/h2&gt;
&lt;p&gt;Just like any business, having too many or too little managers can be problematic.
When it comes to provisioning managers in a Docker Swarm, you want to strike the
right balance of &lt;strong&gt;resiliency&lt;/strong&gt; and &lt;strong&gt;performance&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s touch first on resiliency.&lt;/p&gt;
&lt;h3 id=&#34;resiliency&#34;&gt;Resiliency&lt;/h3&gt;
&lt;p&gt;One of the primary reasons why we are using an orchestration engine like Docker
Swarm is so that we can have a degree of fault tolerance. If any particular
node in the swarm decides to take an &amp;ldquo;unnannounced vacation&amp;rdquo;, we should be able
to schedule whatever tasks (containers that comprise a service) to a different,
active node.&lt;/p&gt;
&lt;p&gt;We have to be particularly strategic to provide this fault tolerance when it comes
to managers. After all, they are responsible for taking on some pretty important
and necessary tasks. In order to best understand how many managers we should
deploy, we should quickly touch on the algorithm Docker Swarm uses to ensure
consistent state.&lt;/p&gt;
&lt;h4 id=&#34;raft-consensus-algorithm&#34;&gt;Raft Consensus Algorithm&lt;/h4&gt;
&lt;p&gt;Sounds fancy right?&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;http://thesecretlivesofdata.com/raft/&#34;&gt;Raft Consensus Algorithm&lt;/a&gt; is essentially an algorithm that
Docker Swarm uses to make sure each manager in the cluster is storing the same
consistent state. The most important thing to note in the context of this discussion
is that manager nodes need to agree on what the state is, and that &amp;ldquo;agreement&amp;rdquo;
is achieved as a function of how many nodes share the same information. If the
majority, also referred to as a &amp;ldquo;quorum&amp;rdquo;, is achieved when new state is proposed,
then it will be distributed to all managers.&lt;/p&gt;
&lt;p&gt;Approaching this mathematically, we can essentially use the following simple
equations to determine achievable fault tolerance and quorum:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;given:
  N = the number of manager nodes in the cluster.

then:
  number of manager nodes that can be down = (N-1)/2
  number of manager nodes to achieve quorum = (N/2)+1
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;EXAMPLE:&lt;/em&gt;&lt;/strong&gt; Assuming we have &lt;code&gt;3&lt;/code&gt; manager nodes (&lt;code&gt;N = 3&lt;/code&gt;) in a cluster of &lt;code&gt;5&lt;/code&gt;
total nodes, we would be able to support &lt;code&gt;1&lt;/code&gt; manager node being down at any
moment in time (&lt;code&gt;(3-1)/2 = 1&lt;/code&gt;). The number of manager nodes to reach quorum
would be &lt;code&gt;2&lt;/code&gt; (&lt;code&gt;(3/2)+1 = 2&lt;/code&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ultimately, the number of managers you deploy in your cluster depends somewhat
on the total number of nodes in your cluster. It is recommended you have at least
&lt;code&gt;3&lt;/code&gt; manager nodes, as such a configuration allows for one manager node to be down.&lt;/p&gt;
&lt;h3 id=&#34;performance&#34;&gt;Performance&lt;/h3&gt;
&lt;p&gt;As with much in software design, the resiliency comes at a cost. Since one element
of increasing the resiliency involves introducing redundency, more work is required
to spread information as we introduce more managers. Adding more manager nodes,
means more managers are needed to meet quorum.&lt;/p&gt;
&lt;p&gt;When it comes to Docker Swarm, it&amp;rsquo;s generally &lt;a href=&#34;https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/#manager-nodes&#34;&gt;not recommended to have any more
than &lt;code&gt;7&lt;/code&gt; manager nodes&lt;/a&gt;. Such a configuration would allow &lt;code&gt;3&lt;/code&gt;
managers to be simultaneously down at any moment and require &lt;code&gt;4&lt;/code&gt; nodes to reach
quorum.&lt;/p&gt;
&lt;h3 id=&#34;unreachable-quorum&#34;&gt;Unreachable Quorum&lt;/h3&gt;
&lt;p&gt;In the event that the number of manager nodes simultaneously down exceeds the
allowable fault tolerance, the state of the cluster is not allowed to change.
New tasks cannot be scheduled, and the existing tasks cannot be rebalanced to
other nodes if required. The following error will be returned when a management
operation is attempted:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Error response from daemon: rpc error: code = 4 desc = context deadline exceeded
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The ideal way to recover here is to get manager nodes back online. If for some
reason the managers can&amp;rsquo;t be brought back online, a new cluster will need to
be provisioned. This can be performed using the following command:&lt;/p&gt;



  &lt;div class=&#34;collapsable-code&#34;&gt;
    &lt;input id=&#34;1&#34; type=&#34;checkbox&#34;  /&gt;
    &lt;label for=&#34;1&#34;&gt;
      &lt;span class=&#34;collapsable-code__language&#34;&gt;bash&lt;/span&gt;
      
      &lt;span class=&#34;collapsable-code__toggle&#34; data-label-expand=&#34;Show&#34; data-label-collapse=&#34;Hide&#34;&gt;&lt;/span&gt;
    &lt;/label&gt;
    &lt;pre class=&#34;language-bash&#34; &gt;&lt;code&gt;
$ docker swarm init --force-new-cluster --advertise-addr &amp;lt;IP&amp;gt;:2377
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;p&gt;Make sure to replace &lt;code&gt;&amp;lt;IP&amp;gt;&lt;/code&gt; with the IP address or DNS resolvable name of the
host you desire to be the initial manager of this new cluster.&lt;/p&gt;
&lt;h4 id=&#34;workers-get-shit-done&#34;&gt;Workers Get Shit Done&lt;/h4&gt;
&lt;p&gt;Compared to manager nodes, worker nodes are far simpler. Since they are
designated for executing the tasks for the swarm, the main deployment concerns
are simply ensuring that there are enough workers to balance the load.&lt;/p&gt;
&lt;p&gt;To join an existing swarm cluster as a worker node, run the following commands
to retrieve the worker join token:&lt;/p&gt;



  &lt;div class=&#34;collapsable-code&#34;&gt;
    &lt;input id=&#34;3&#34; type=&#34;checkbox&#34;  /&gt;
    &lt;label for=&#34;3&#34;&gt;
      &lt;span class=&#34;collapsable-code__language&#34;&gt;bash&lt;/span&gt;
      
      &lt;span class=&#34;collapsable-code__toggle&#34; data-label-expand=&#34;Show&#34; data-label-collapse=&#34;Hide&#34;&gt;&lt;/span&gt;
    &lt;/label&gt;
    &lt;pre class=&#34;language-bash&#34; &gt;&lt;code&gt;
$ docker swarm join-token worker
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;p&gt;Assuming the above command provided this output:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;docker swarm join \
  --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
  192.168.99.100:2377
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The final step would be to run that command:&lt;/p&gt;



  &lt;div class=&#34;collapsable-code&#34;&gt;
    &lt;input id=&#34;4&#34; type=&#34;checkbox&#34;  /&gt;
    &lt;label for=&#34;4&#34;&gt;
      &lt;span class=&#34;collapsable-code__language&#34;&gt;bash&lt;/span&gt;
      
      &lt;span class=&#34;collapsable-code__toggle&#34; data-label-expand=&#34;Show&#34; data-label-collapse=&#34;Hide&#34;&gt;&lt;/span&gt;
    &lt;/label&gt;
    &lt;pre class=&#34;language-bash&#34; &gt;&lt;code&gt;
$ docker swarm join \
  --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
  192.168.99.100:2377
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/em&gt;: When adding workers to accommodate for expected or current
workloads, make sure to take the various resource related requirements that
may be specified for a particular service. Remember that workers that
don&amp;rsquo;t meet those specified requirements will not be scheduled to execute
those tasks.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
    </item>
    
    <item>
      <title>Building a Pi Cluster</title>
      <link>/posts/building-a-pi-cluster/</link>
      <pubDate>Sat, 06 Aug 2022 21:22:01 -0700</pubDate>
      
      <guid>/posts/building-a-pi-cluster/</guid>
      <description>Having been a software engineer for years, I had heard about Raspberry Pi computers, and the tinkering people were doing with them. Despite the chatter, I didn&amp;rsquo;t have any sort of project in mind, and honestly didn&amp;rsquo;t take the time to learn about them.
One year when the holiday season began rolling around, the team decided to partake in a &amp;ldquo;secret santa&amp;rdquo; gift giving activity. Without any better ideas, I put down that I was interesting an a Raspberry Pi.</description>
      <content>&lt;p&gt;Having been a software engineer for years, I had heard about Raspberry Pi
computers, and the tinkering people were doing with them. Despite the chatter,
I didn&amp;rsquo;t have any sort of project in mind, and honestly didn&amp;rsquo;t take the time
to learn about them.&lt;/p&gt;
&lt;p&gt;One year when the holiday season began rolling around, the
team decided to partake in a &amp;ldquo;secret santa&amp;rdquo; gift giving activity. Without any
better ideas, I put down that I was interesting an a Raspberry Pi.&lt;/p&gt;
&lt;p&gt;Fast-forward 3 years later and I finally found a project that I was genuinely
excited about: creating a Raspberry Pi cluster. I dug up that model 3B+ that I
got from the gift exchange years prior to began setting it up for the first
time, and I&amp;rsquo;ve been at it ever since!&lt;/p&gt;
&lt;h1 id=&#34;hardware&#34;&gt;Hardware&lt;/h1&gt;
&lt;p&gt;In order to build a Raspberry Pi cluster, you need some gear! Lets walk through
the various items I ended up with.&lt;/p&gt;
&lt;h4 id=&#34;pis&#34;&gt;Pis&lt;/h4&gt;
&lt;p&gt;The most important part of the Pi cluster is&amp;hellip; well&amp;hellip; the Pis!&lt;/p&gt;
&lt;p&gt;I received one as a gift - check! The remaining three I needed to source internationally
(more on that later). To future proof, I was aiming for the model 4B. Although
it would&amp;rsquo;ve been nice to get my hands on a 4GB or 8GB configuration, they were
basically myths during these times. I settled for three 2GB models.&lt;/p&gt;
&lt;h4 id=&#34;poe-hats&#34;&gt;PoE+ Hats&lt;/h4&gt;
&lt;p&gt;Given power supplies aren&amp;rsquo;t included with the Pi itself, I knew that powering
my cluster was going to involve spending some additional money.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.adafruit.com/product/4298?gclid=Cj0KCQjwxb2XBhDBARIsAOjDZ37bms37yK_7GGNQR5pZ6oqvTZTzyaVe16QH8_NynBC47z0yp6GJZc0aAgFnEALw_wcB&#34;&gt;official power supply&lt;/a&gt; goes for around $8 dollars. Knowing that I was going to shoot for 4 Pis, that was going
to cost me $32 dollars. That wasn&amp;rsquo;t even including the money I&amp;rsquo;d need to spend
on zip ties and the time I&amp;rsquo;d need to spend to cable manage. Lastly, I simply
couldn&amp;rsquo;t justify using 4 outlets!&lt;/p&gt;
&lt;p&gt;This is where &lt;a href=&#34;https://en.wikipedia.org/wiki/Power_over_Ethernet&#34;&gt;Power over Ethernet (PoE)&lt;/a&gt; comes to the rescue. With the correct
networking equipment, enough power to drive the Pis can be delivered over a
simple ethernet cable. No more outlet waste or time spent cable managing! But
there is one catch.&lt;/p&gt;
&lt;p&gt;The Pis themselves can&amp;rsquo;t be powered over ethernet. An &lt;a href=&#34;https://www.adafruit.com/product/5058&#34;&gt;additional hat&lt;/a&gt; needs to
be purchased to achieve this, and they aren&amp;rsquo;t exactly cheap. That said, they
are well worth the price. They are super easy to install on the Pis, plenty of
cases have enough space for them, and they solve the gripes around multiple
power supplies.&lt;/p&gt;
&lt;h4 id=&#34;switch&#34;&gt;Switch&lt;/h4&gt;
&lt;p&gt;When it comes to PoE+ switches, the main thing to focus on is the number of ports.
Obviously, the more ports, the more you will end up spending. No more than 4 Pis
are needed for my build, so I went with the &lt;a href=&#34;https://www.amazon.com/dp/B08LHL1Q2Z?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details&#34;&gt;Netgear GS305P (v2)&lt;/a&gt;. This switch
is &lt;a href=&#34;https://www.fieldengineer.com/blogs/network-switch-managed-vs-unmanaged#:~:text=An%20unmanaged%20switch%20is%20simple,systems%20to%20a%20larger%20network.&#34;&gt;unmanaged&lt;/a&gt; (no smartness) and has 5 ports, one of which being the ingress from your existing internet connection.&lt;/p&gt;
&lt;h4 id=&#34;storage&#34;&gt;Storage&lt;/h4&gt;
&lt;p&gt;Each Pi has a micro SD card slot that acts as onboard storage. For my use cases,
I knew I was going to use a network attached storage (NAS) device to store all
of my data, so using a smaller SD card made sense. I ultimately landed on
snagging some &lt;a href=&#34;https://www.officedepot.com/a/products/8224492/SanDisk-Ultra-PLUS-microSD-Cards-32GB/&#34;&gt;SanDisk 32GB cards&lt;/a&gt;, which will be plenty of space for my needs.&lt;/p&gt;
&lt;h4 id=&#34;cables&#34;&gt;Cables&lt;/h4&gt;
&lt;p&gt;To deliver both power and data to the Pis, I needed some ethernet cables. My
only desire for these was that they were small (also called &lt;a href=&#34;https://www.cables.com/cablesblog/ethernet-vs-patch-cables-whats-the-difference.html&#34;&gt;patch cables&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;I found that cables were typically sized in 6 inch increments. Many places
didn&amp;rsquo;t sell patch cables smaller than 1 foot, but I eventually found &lt;a href=&#34;https://www.amazon.com/dp/B06XC5PZLV?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details&#34;&gt;some&lt;/a&gt; online
without too much trouble.&lt;/p&gt;
&lt;p&gt;If you are looking for any slack at all, I&amp;rsquo;d recommend getting cables that are about
1 foot in length. Additionally, my cables all weren&amp;rsquo;t the exact same size, so
if sizing consistency is super important, I wouldn&amp;rsquo;t buy the cables I ended up
getting.&lt;/p&gt;
&lt;h4 id=&#34;case&#34;&gt;Case&lt;/h4&gt;
&lt;p&gt;Now that I had picked out all of my parts, I needed a case to put it in. After
a little digging, I stumbled upon &lt;a href=&#34;https://www.uctronics.com/&#34;&gt;Uctronics&lt;/a&gt; which produces many &lt;a href=&#34;https://www.uctronics.com/cluster-and-rack-mount/for-raspberry-pi/cluster.html&#34;&gt;products
specific to Pi clusters&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In particular, I wanted something that could not only house my Pis (keeping in
mind they each would have a PoE+ hat installed), but also something that would
also house my PoE+ switch, and provide simple access to the Pis in case I needed
change anything.&lt;/p&gt;
&lt;h1 id=&#34;cost-breakdown&#34;&gt;Cost Breakdown&lt;/h1&gt;
&lt;p&gt;Below outlines the cost of my build (excluding state-side taxes; VAT was included in some
of the purchases). Keep in mind that the chip shortage, high inflation, and
supply chain woes led to higher costs than what was likely achievable historically
for the same parts.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Line Item&lt;/th&gt;
&lt;th&gt;Price ($)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.adafruit.com/product/3775&#34;&gt;Raspberry Pi 3B+ (1GB)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$35.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Raspberry Pi 4B (2GB)&lt;/td&gt;
&lt;td&gt;$52.92&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Raspberry Pi 4B (2GB)&lt;/td&gt;
&lt;td&gt;$45.78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Raspberry Pi 4B (2GB)&lt;/td&gt;
&lt;td&gt;$45.79&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.adafruit.com/product/2336&#34;&gt;Crappy Standoffs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$8.16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.mouser.com/ProductDetail/RAF-Electronic-Hardware/M2104-2545-AL?qs=2411ckis64rpgA%252BYlrCb%252Bg%3D%3D&#34;&gt;Good Standoffs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$22.73&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.amazon.com/UCTRONICS-Upgraded-Enclosure-Raspberry-Removable/dp/B09JNHKL2N&#34;&gt;Case&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$69.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.amazon.com/dp/B09TP9HT3C?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details&#34;&gt;Case Fan Adaptor&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$5.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.amazon.com/dp/B08LHL1Q2Z?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details&#34;&gt;Switch&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$69.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.adafruit.com/product/5058&#34;&gt;PoE+ Hat&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$20.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.adafruit.com/product/5058&#34;&gt;PoE+ Hat&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$20.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.adafruit.com/product/5058&#34;&gt;PoE+ Hat&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$20.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.adafruit.com/product/5058&#34;&gt;PoE+ Hat&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$20.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.amazon.com/dp/B06XC5PZLV?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details&#34;&gt;Cables&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$14.49&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.officedepot.com/a/products/8224492/SanDisk-Ultra-PLUS-microSD-Cards-32GB/&#34;&gt;Micro SD Card (x2)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$22.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.officedepot.com/a/products/8224492/SanDisk-Ultra-PLUS-microSD-Cards-32GB/&#34;&gt;Micro SD Card (x2)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;$22.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Shipping&lt;/td&gt;
&lt;td&gt;$76.76&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Total&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;$570.61&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I was also very fortunate in that the Raspberry Pi 3B+ was a gift (as mentioned
previously) and that I had accumulated some Adafruit gift cards up to this point!&lt;/p&gt;
&lt;h1 id=&#34;what-went-not-so-well&#34;&gt;What went not so well&lt;/h1&gt;
&lt;h4 id=&#34;incomplete-case&#34;&gt;Incomplete Case&lt;/h4&gt;
&lt;p&gt;Even though the quality of the case I got was solid, it was annoyingly incomplete.&lt;/p&gt;
&lt;p&gt;The first strike with the case was that it came with fans that could be powered
by the Pi, but didn&amp;rsquo;t include the adaptor necessary. I actually didn&amp;rsquo;t realize
this until I was building the case, as the instruction manual that came with it
referenced the part but it wasn&amp;rsquo;t included. I find it pretty strange that the fans
come with the case but the adaptor isn&amp;rsquo;t included.&lt;/p&gt;
&lt;p&gt;My next gripe was that the case avertises that it is compatible with the
PoE+ hat, but didn&amp;rsquo;t come equipped with standoffs compatible with the case.
Instead it came with screws to secure the Pis to the trays, which would essentially
be all that is necessary if there were no hats installed. I give Uctronics more
of a pass here, given not all builds will use hats, but found the advertising
misleading.&lt;/p&gt;
&lt;p&gt;These shortcomings were the only reason I needed to purchase the standoffs and
the fan adaptor, resulting in a total investment in the case to be ~$85, which
I found to be pretty expensive - more expensive than the &lt;a href=&#34;https://www.amazon.com/Thermaltake-Suppressor-Certified-Computer-CA-1E6-00S1WN-00/dp/B017NWO5V2&#34;&gt;case&lt;/a&gt; I have for my mini-ITX
build.&lt;/p&gt;
&lt;h4 id=&#34;lack-of-pi-availability&#34;&gt;(Lack of) Pi Availability&lt;/h4&gt;
&lt;p&gt;My interest in creating a Raspberry Pi cluster couldn&amp;rsquo;t have been piqued at a
worse time in terms of availability. Due to both &lt;a href=&#34;https://www.raspberrypi.com/news/production-and-supply-chain-update/&#34;&gt;supply constraints and increased
demand&lt;/a&gt;, they have been nearly impossible to comeby.&lt;/p&gt;
&lt;p&gt;After quickly learning that there was no way I was going to be able to purchase
my Pis from &lt;a href=&#34;https://www.adafruit.com/&#34;&gt;Adafruit&lt;/a&gt;, &lt;a href=&#34;https://www.digikey.com/&#34;&gt;Digikey&lt;/a&gt;, or any other retailer I was a previous customer of,
I briefly looked at alternative marketplaces such as Facebook. It was clear that
was going to be a dead-end as well since the only sellers were gouging hard; we&amp;rsquo;re
talking $100+ for model 4B (2G) which &lt;a href=&#34;https://www.adafruit.com/product/4292&#34;&gt;normally retails for $45&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I finally discovered a website called &lt;a href=&#34;https://rpilocator.com/&#34;&gt;rpilocator&lt;/a&gt;, which was
completely dedicated to help solving this issue. It was through this website that
I was fortunate enough to snag three model 4B (2G) Pis.&lt;/p&gt;
&lt;p&gt;This wasn&amp;rsquo;t a quick process though; it took 2-3 months for the timing to line up right.
It&amp;rsquo;s also worth mentioning that nearly all of these vendor websites have a policy of
one Pi per customer, which made things more difficult. I even saw various vendors
adapt very strict policies that only previously existing customers could purchase them, or that
they were no longer going to ship them internationally.&lt;/p&gt;
&lt;h4 id=&#34;cost&#34;&gt;Cost&lt;/h4&gt;
&lt;p&gt;Although there were certainly some market elements that were out of my control
that contributed to the overall price (particularly shipping), there was opportunity
to cut costs in several areas.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Power Supplies vs. PoE Switch&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In total, I spent $150 dollars on the PoE+ specific line items alone. Assuming
you already have an existing switch with 4 available ports, as well as 4 available
power outlets, that would translate to avoiding around $115 of cost, given you&amp;rsquo;d
need to purchase the power supplies instead (around $32 + shipping).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As previously mentioned, I ended up sinking $85 into my case for the Pi cluster.
Sure it came with some frills, but it&amp;rsquo;s arguable whether they justify the extra bucks.
It would definitely be possible to get away with a $15 dollar case like &lt;a href=&#34;https://vilros.com/products/vilros-acrylic-4-layer-clear-case-box-enclosure-for-raspberry-pi?variant=29408411877470&amp;amp;currency=USD&amp;amp;utm_medium=product_sync&amp;amp;utm_source=google&amp;amp;utm_content=sag_organic&amp;amp;utm_campaign=sag_organic&amp;amp;gclid=EAIaIQobChMI9ZLJzbC7-QIV9AjnCh0WpAUbEAQYASABEgLszPD_BwE&#34;&gt;this one&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;what-went-well&#34;&gt;What went well&lt;/h1&gt;
&lt;h4 id=&#34;customer-service&#34;&gt;Customer Service&lt;/h4&gt;
&lt;h5 id=&#34;international-shipping&#34;&gt;International Shipping&lt;/h5&gt;
&lt;p&gt;Before this project, I really hadn&amp;rsquo;t made an international purchase online before.
For the most part, it was made far easier thanks to rpilocater, as many of the
websites listing inventory were not written in english, and translating the content
was hit or miss. Luckily I was able to stumble my way through check out.&lt;/p&gt;
&lt;p&gt;Waiting for the Pis to be shipped was far harder. In particular, one
of the Pis I bought stated that it had been shipped to the US, but when I looked
up the tracking number on the USPS website, it claimed it had never been received.
Calling the USPS, was less than helpful, but my email interactions with the staff
of the store I bought it from were really great - and most importantly, transparent.
They were knowledgable of the customs shipping process and the state of global
shipping, hopeful I&amp;rsquo;d get it, and remarked that they had just recently gotten
into international shipping. The positivity they had gave me that extra boost
of stamina for the long wait!&lt;/p&gt;
&lt;h5 id=&#34;standoff-snafu&#34;&gt;Standoff Snafu&lt;/h5&gt;
&lt;p&gt;Okay, so now I had the Pis - great! Next it was time to screw in these
bad boys and get them up and running.&lt;/p&gt;
&lt;p&gt;When it came time to install these things into my newly purchased case, I had
bought some standoffs that were a compatible height to support the PoE+ hats I was using. I made
sure that they were M2.5 sized to match the screws provided with the &lt;a href=&#34;https://www.mouser.com/ProductDetail/RAF-Electronic-Hardware/M2104-2545-AL?qs=2411ckis64rpgA%252BYlrCb%252Bg%3D%3D&#34;&gt;case&lt;/a&gt;
itself; check!&lt;/p&gt;
&lt;p&gt;Weirdly, on some of the tray mounts, the screws wouldn&amp;rsquo;t turn easily. I naively
thought it they needed an extra &amp;lsquo;oomf&amp;rsquo; to get them to the desired position, so
of course I reached for my pliers!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: Don&amp;rsquo;t use pliers to install standoffs into the case.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Without too much additional manpower, I managed to snap off the threaded portion
of a standoff in the tray mount point. Game over! Sure, I could&amp;rsquo;ve just not
screwed in a standoff for that one corner, but then it just wouldn&amp;rsquo;t be complete!
Also, since the GPIO pins are used to connect the hat and the Pi, I didn&amp;rsquo;t
want to have to worry about accidentally squishing that limp corner too hard when
working with it in the future. I had to fix this.&lt;/p&gt;
&lt;p&gt;I reached out to UCTRONICS support via their website directly. I explained to
them what happened, and they were incredible. They shipped not one, but two replacement
trays all for something that was completely my fault.&lt;/p&gt;
&lt;p&gt;Best of all, thanks to Jeff Gerling and &lt;a href=&#34;https://github.com/geerlingguy/raspberry-pi-dramble/issues/135&#34;&gt;his prior research&lt;/a&gt;, I went ahead and ordered a second
set of standoffs with the hope that I&amp;rsquo;d get it right the second time - it worked like a charm!&lt;/p&gt;
&lt;h4 id=&#34;availability&#34;&gt;Availability&lt;/h4&gt;
&lt;h1 id=&#34;was-the-cost-worth-it&#34;&gt;Was the cost worth it?&lt;/h1&gt;
&lt;p&gt;So was the cost worth it? With so many different Infrastructure as a Service (IaaS)
companies such as Linode, Amazon Web Service (AWS), etc. this is a question
that gets asked more an more.&lt;/p&gt;
&lt;p&gt;To get a sense of this, let&amp;rsquo;s consider what the cost could be if I were to choose
a provider such as Linode to host my cluster instead.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: This is a rough comparison, as the exact specs of my build are not
a purchasable configuration.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;contender-1-pi-cluster&#34;&gt;Contender #1: Pi Cluster&lt;/h4&gt;
&lt;p&gt;To kick this off, let&amp;rsquo;s get an idea of the (estimated) all in costs for the Pi cluster.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve already highlighted the hardware costs above, but what about electricity costs?
Since all of the Pis are being powered by a single PoE+ switch, we can compute the
electricity costs by determining the power usage of the switch and how long we plan
to have it running.&lt;/p&gt;
&lt;p&gt;With all ports utilized (which they are), the switch can draw up to 60W of power.
I plan on keeping this cluster up and running all day, everyday. Lastly, we&amp;rsquo;ll
need to factor in average electricity rates for my state.&lt;/p&gt;
&lt;p&gt;With the help of &lt;a href=&#34;https://www.energy.gov/energysaver/maps/appliance-energy-calculator&#34;&gt;this calculator&lt;/a&gt;, it appears that all adds up to ~$131 annually.
Using simple maths, I came up with the following breakdown (rounding up the hardware costs to $550):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Configuration&lt;/th&gt;
&lt;th&gt;Up Front Cost&lt;/th&gt;
&lt;th&gt;Cost per Month&lt;/th&gt;
&lt;th&gt;After 6 Months&lt;/th&gt;
&lt;th&gt;After 12 Months&lt;/th&gt;
&lt;th&gt;After 18 Months&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Pi Cluster&lt;/td&gt;
&lt;td&gt;~$550&lt;/td&gt;
&lt;td&gt;$11&lt;/td&gt;
&lt;td&gt;$616&lt;/td&gt;
&lt;td&gt;$682&lt;/td&gt;
&lt;td&gt;$748&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;contender-2-linode&#34;&gt;Contender #2: Linode&lt;/h4&gt;
&lt;p&gt;First, let&amp;rsquo;s take a look at some &lt;a href=&#34;https://www.linode.com/products/shared/&#34;&gt;Linode shared hosting&lt;/a&gt; plans:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Plan&lt;/th&gt;
&lt;th&gt;CPU Core Count&lt;/th&gt;
&lt;th&gt;Cost per Month&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Linode 2GB&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;$10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linode 4GB&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;$20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linode 8GB&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;$40&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;My cluster has 16 CPU cores (each Pi has 4) and a total of 7GB of RAM. To attempt a fair comparison,
I&amp;rsquo;ll break down the comparisons into two sections: matching RAM and matching CPU.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matching RAM&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The following configurations achieve 8GB RAM.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Configuration&lt;/th&gt;
&lt;th&gt;Cost per Month&lt;/th&gt;
&lt;th&gt;After 6 Months&lt;/th&gt;
&lt;th&gt;After 12 Months&lt;/th&gt;
&lt;th&gt;After 18 Months&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;4 x Linode 2GB&lt;/td&gt;
&lt;td&gt;$40&lt;/td&gt;
&lt;td&gt;$240&lt;/td&gt;
&lt;td&gt;$480&lt;/td&gt;
&lt;td&gt;$720&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 x Linode 4GB&lt;/td&gt;
&lt;td&gt;$40&lt;/td&gt;
&lt;td&gt;$240&lt;/td&gt;
&lt;td&gt;$480&lt;/td&gt;
&lt;td&gt;$720&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 x Linode 8GB&lt;/td&gt;
&lt;td&gt;$40&lt;/td&gt;
&lt;td&gt;$240&lt;/td&gt;
&lt;td&gt;$480&lt;/td&gt;
&lt;td&gt;$720&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;With this approach, my Pi cluster would prove to be more cost effective after &lt;strong&gt;~19 months&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matching CPU Core Count&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The following configurations achieve 16 CPU cores.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Configuration&lt;/th&gt;
&lt;th&gt;Cost per Month&lt;/th&gt;
&lt;th&gt;After 6 Months&lt;/th&gt;
&lt;th&gt;After 12 Months&lt;/th&gt;
&lt;th&gt;After 18 Months&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;16 x Linode 2GB&lt;/td&gt;
&lt;td&gt;$160&lt;/td&gt;
&lt;td&gt;$960&lt;/td&gt;
&lt;td&gt;$1920&lt;/td&gt;
&lt;td&gt;$2880&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8 x Linode 4GB&lt;/td&gt;
&lt;td&gt;$160&lt;/td&gt;
&lt;td&gt;$960&lt;/td&gt;
&lt;td&gt;$1920&lt;/td&gt;
&lt;td&gt;$2880&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 x Linode 8GB&lt;/td&gt;
&lt;td&gt;$160&lt;/td&gt;
&lt;td&gt;$960&lt;/td&gt;
&lt;td&gt;$1920&lt;/td&gt;
&lt;td&gt;$2880&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;With this approach, my Pi cluster would prove to be more cost effective after &lt;strong&gt;~3.75 months&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;Yes, at least for me it was worth it, but only because I plan on hosting this
cluster in perpituity, want to have the extra control over my data, and want the
performance of dedicated hosting. The experience of learning how to build the
cluster from scratch is also an added educational bonus.&lt;/p&gt;
&lt;p&gt;To be honest though, this experience showed me that it&amp;rsquo;s probably better to at
least start out by using an IaaS platform. Depending on the configuration, you
could achieve a comparable setup that is actually cheaper for 12 or even 18 months.&lt;/p&gt;
&lt;p&gt;I hope you enjoyed following along! Have any ideas for what I should use my
Pi cluster for? Toss me a comment and maybe I&amp;rsquo;ll give it a try. Also, I can&amp;rsquo;t
wait to bring you all along for what I might do with this next - there is so
much out there!&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
