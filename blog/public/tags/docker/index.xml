<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>docker on /* Commentary */</title>
    <link>/tags/docker/</link>
    <description>Recent content in docker on /* Commentary */</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Feb 2023 21:51:53 -0800</lastBuildDate><atom:link href="/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Writing Better Docker Swarm Stacks</title>
      <link>/posts/organizing-docker-swarm-stacks/</link>
      <pubDate>Fri, 10 Feb 2023 21:51:53 -0800</pubDate>
      
      <guid>/posts/organizing-docker-swarm-stacks/</guid>
      <description>When I decided to stand up my home lab, I had little to no prior experience with Docker Swarm or other supporting infrastructure (shared storage, node provisioning, etc.) and applications (Portainer, NAS software, etc.). The process of building out my cluster has been packed with learnings from both the good and the bad experiences I&amp;rsquo;ve had along the way. Additionally, I&amp;rsquo;ve picked up some patterns and practices that have helped me get to where everything is today.</description>
      <content>&lt;p&gt;When I decided to stand up my home lab, I had little to no prior experience
with Docker Swarm or other supporting infrastructure (shared storage,
node provisioning, etc.) and applications (Portainer, NAS software, etc.). The process of
building out my cluster has been packed with learnings from both the good and
the bad experiences I&amp;rsquo;ve had along the way. Additionally, I&amp;rsquo;ve picked up some
patterns and practices that have helped me get to where everything is today.&lt;/p&gt;
&lt;p&gt;One area specifically worth sharing is regarding Docker Compose (stack) files.
This post walks through the most critical bits that inform how I organize
and write my stack files.&lt;/p&gt;
&lt;h3 id=&#34;multiple-stack-files&#34;&gt;Multiple Stack Files&lt;/h3&gt;
&lt;p&gt;It can be tempting to put all of your service definitions in a single stack file at first.
After all, it means you only have one file to worry about; everything is in a single place.
Also, you don&amp;rsquo;t have to worry about setting up a directory structure to organize - keeping things
tidy takes effort!&lt;/p&gt;
&lt;p&gt;However, I encourage you to fight the urge. There are some really tangible benefits
to breaking your stack files down by application:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Each stack file becomes self contained. The services defined in the stack file
are specific to a partular application you are spinning up. All of the volumes,
networks, etc. are all specific to the service definitions in the file; you&amp;rsquo;re no
longer trying to determine how everything ties together.&lt;/li&gt;
&lt;li&gt;Separating the files means you can deploy a finite set of services at a time
instead of all of them. This helps make your deployments more manageable and
ensures that you aren&amp;rsquo;t going to have unintended side-effects with other
services.&lt;/li&gt;
&lt;li&gt;There is less likelihood that you will accidentally reference an element
unintentionally or have a naming clash. If performing variable substitution, you
won&amp;rsquo;t have to worry about inadvertently giving two variables the same name.&lt;/li&gt;
&lt;li&gt;Each stack file is simply easier to read. Any one application usually doesn&amp;rsquo;t have
more than a few services (web server, database, cache, etc.) which is easier to
navigate than a single file with dozens of services.&lt;/li&gt;
&lt;li&gt;Tools such as Portainer provide an interface for managing stacks separate from
the services they define. With the files broken out by application, you can
manage each stack independently using the UI.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As with anything, there are some drawbacks. When splitting out files, you
likely will have to repeat particular dependency definitions that various services of
yours utilize. For example, you will need to replicate a network definition in
each stack file that defines services that should be a part of that network. In
the event you need to change one of those dependencies, you will need to visit multiple
stack files to apply that change, which is a measurable amount of more work.&lt;/p&gt;
&lt;p&gt;For me, the benefits outweighed drawbacks.&lt;/p&gt;
&lt;h3 id=&#34;service-naming-conventions&#34;&gt;Service Naming Conventions&lt;/h3&gt;
&lt;p&gt;Every stack file defines a list of services. Often times your stack will
define a single service. However, some applications that you wish to deploy
could be more complex, including a web server, database, cache, job queue,
and more.&lt;/p&gt;
&lt;p&gt;When it comes to naming these services, I&amp;rsquo;ve found that naming them after the
role they play as the most effective. More specifically, I use the following
within my stacks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;app&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;db&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cache&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;queue&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are many reasons why this strategy has worked for me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The service names aren&amp;rsquo;t coupled to any particular implementation, which means
that switching them to something else ( let&amp;rsquo;s say, switching from &lt;code&gt;Redis&lt;/code&gt; to &lt;code&gt;Memcache&lt;/code&gt; )
won&amp;rsquo;t ripple up to the service names.&lt;/li&gt;
&lt;li&gt;It&amp;rsquo;s easier to navigate your services. All your database services are end in&lt;code&gt;db&lt;/code&gt;.
All of your caches are end in &lt;code&gt;cache&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Since service names are prefixed by the name of the stack they belong to, this
strategy results in service names that avoid commonly seen mistakes, such
as repetitive words within the name.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pinning-to-specific-image-versions&#34;&gt;Pinning to Specific Image Versions&lt;/h3&gt;
&lt;p&gt;It&amp;rsquo;s easy to leave off a specific image version or to specify &lt;code&gt;latest&lt;/code&gt;.
However, this can really burn you, and typically at the worst time. Instead,
you should explicitly specify an image version (tag).&lt;/p&gt;
&lt;p&gt;Why? Well the are several reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In a cluster environment, images are pulled down on each node when the service is scheduled to run on them.
If at any time you add in additional nodes, or deploy to a node you hadn&amp;rsquo;t previously, it is possible
that the images on each node for the service aren&amp;rsquo;t the same. After all, &lt;code&gt;latest&lt;/code&gt;
is a moving target, and it&amp;rsquo;s not trivial to determine when new releases are cut.&lt;/li&gt;
&lt;li&gt;In situations where your node(s) experience a more catestrophic event (hardware
failure, botched OS upgrade, etc.) restoring the data and configuration for the
service(s) is half the battle, but running a version of the service compatible
with that configuration and data is the other half. Remember that the data and configuration that one
version of your service utilizes could be completely different from the current
(latest), and the last thing you want to do is spend time triaging errors that
are only happening because you&amp;rsquo;re running an incompatible version.&lt;/li&gt;
&lt;li&gt;It becomes much more apparent what version you are running for your services,
which makes it easier to search for bugs, documentation, and other artifacts
online.&lt;/li&gt;
&lt;li&gt;Upgrading your services becomes more intentional. You specify the next version you
want to upgrade to explicitly. This approach can help you avoid upgrading to
versions known to be less stable or haven&amp;rsquo;t been well tested yet.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;source-control-for-stack-files&#34;&gt;Source Control for Stack Files&lt;/h3&gt;
&lt;p&gt;Your stack files are essentially the source of truth for your cluster setup;
you should manage and track changes to them so you keep your sanity! So much tweaking,
changing, improving, and learning happens when you work in a cluster environment.
It&amp;rsquo;s going to be near impossible to keep all of those learnings in recent memory.
Using source control is an incredibly helpful tool to track all of that context
for future you, while also giving you the safety net of being able to roll back
your changes gracefully.&lt;/p&gt;
&lt;p&gt;An awesome side-effect of pushing your stack files to a remote source control
such as GitHub is applications like Portainer can integrate directly with
your stack repositories. This means you can make changes to your stacks and
push them to GitHub, and then you can use Portainer to deploy those changes.&lt;/p&gt;
&lt;h3 id=&#34;utilize-variable-substitution-for-image-tag&#34;&gt;Utilize Variable Substitution for Image Tag&lt;/h3&gt;
&lt;p&gt;Docker compose (stack) files support &lt;a href=&#34;https://docs.docker.com.xy2401.com/compose/environment-variables&#34;&gt;variable substitution&lt;/a&gt;, which means that
various elements of the stack can be dynamically evaluated based on environment
variables. This is even easier if you use a container management platform such
as Portainer, as it allows you declare the environment variables when you
create a stack directly in the UI.&lt;/p&gt;
&lt;p&gt;There are various use cases one could use variable substitution for, but one
that I strongly recommend is using them to specify the image version (tag). This way
you can manage upgrades for your services by simply changing the environment
variable and redeploying the stack. If you manage your stacks using source countrol
this means you can upgrade the image without any need to change the stack file.&lt;/p&gt;
&lt;h3 id=&#34;leverage-docker-secrets--config&#34;&gt;Leverage Docker Secrets &amp;amp; Config&lt;/h3&gt;
&lt;p&gt;Many services store their configuration using one or more static configuration files.
For example an &lt;code&gt;nginx&lt;/code&gt; proxy may be configured such that each domain that it
handles has a separate &lt;code&gt;*.conf&lt;/code&gt; file. For services that are primarily driven through
updates of static configuration files, &lt;a href=&#34;https://docs.docker.com/engine/swarm/configs/&#34;&gt;Docker Configs&lt;/a&gt; is a perfect fit. Using
Docker Configs in a swarm environment means you can edit these configuration
files in a streamlined and centralized way, can version that configuration,
and no longer need to set up the necessary infrastructure to ensure that
configuration is shared across all nodes that the service runs on.&lt;/p&gt;
&lt;p&gt;An additional common use case for services is specifying credentials. Many Dockerized
applications provide a way to specify credentials via environment variables. Some
services also rely on TLS/SSL configuration. These use cases are where &lt;a href=&#34;https://docs.docker.com/engine/swarm/secrets/&#34;&gt;Docker
Secrets&lt;/a&gt; shines. Instead of passing in credentials using variable subsitution,
or instead of creating infrastructure to share certificate information across
several nodes, you can use Docker Secrets similarly to Docker Configs but for
sensitive &amp;ldquo;secret&amp;rdquo; data.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m just scratching the surface with these. Expect a future blog post on how
I use both of these in my cluster setup!&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Who&#39;s the Boss?</title>
      <link>/posts/docker-swarm-managers/</link>
      <pubDate>Sat, 13 Aug 2022 08:12:39 -0700</pubDate>
      
      <guid>/posts/docker-swarm-managers/</guid>
      <description>Every node in a Docker Swarm plays at least one of two particular roles: worker and/or manager. When you create a new cluster, you start out by creating it with a single node that is both a manager and a worker, and specify an IP address to advertise that manager to other managers as you add them.
Roles So what are the responsibilities of these two roles anyway? How do you know how many managers and workers to deploy in your swarm?</description>
      <content>&lt;p&gt;Every node in a Docker Swarm plays at least one of two particular roles: worker
and/or manager. When you create a new cluster, you start out by creating it with
a single node that is both a manager and a worker, and &lt;a href=&#34;https://docs.docker.com/engine/swarm/admin_guide/#configure-the-manager-to-advertise-on-a-static-ip-address&#34;&gt;specify an IP address
to advertise that manager to other managers&lt;/a&gt; as you add them.&lt;/p&gt;
&lt;h1 id=&#34;roles&#34;&gt;Roles&lt;/h1&gt;
&lt;p&gt;So what are the responsibilities of these two roles anyway? How do you know
how many managers and workers to deploy in your swarm? Let&amp;rsquo;s get into it!&lt;/p&gt;
&lt;h2 id=&#34;managers&#34;&gt;Managers&lt;/h2&gt;
&lt;p&gt;As you might imagine, &lt;a href=&#34;https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/#manager-nodes&#34;&gt;manager nodes&lt;/a&gt; in a Docker Swarm take on
additional cluster management tasks. Such tasks include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;maintaining &amp;amp; distributing cluster state across manager nodes in the cluster&lt;/li&gt;
&lt;li&gt;scheduling services to various nodes in the swarm&lt;/li&gt;
&lt;li&gt;serving swarm mode HTTP API endpoints&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;workers&#34;&gt;Workers&lt;/h2&gt;
&lt;p&gt;Intuitively, &lt;a href=&#34;https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/#worker-nodes&#34;&gt;worker nodes&lt;/a&gt; don&amp;rsquo;t perform any of the management
tasks that the manager nodes do; all that stuff is above the pay grade.
Instead, worker nodes are solely responsible for executing service tasks.&lt;/p&gt;
&lt;h2 id=&#34;promotion--demotion&#34;&gt;Promotion &amp;amp; Demotion&lt;/h2&gt;
&lt;p&gt;Roles for nodes can be changed. To &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/node_promote/&#34;&gt;promote&lt;/a&gt; a worker node to
be a manager node, run the following:&lt;/p&gt;



  &lt;div class=&#34;collapsable-code&#34;&gt;
    &lt;input id=&#34;1&#34; type=&#34;checkbox&#34;  /&gt;
    &lt;label for=&#34;1&#34;&gt;
      &lt;span class=&#34;collapsable-code__language&#34;&gt;bash&lt;/span&gt;
      
      &lt;span class=&#34;collapsable-code__toggle&#34; data-label-expand=&#34;Show&#34; data-label-collapse=&#34;Hide&#34;&gt;&lt;/span&gt;
    &lt;/label&gt;
    &lt;pre class=&#34;language-bash&#34; &gt;&lt;code&gt;
$ docker node promote &amp;lt;NODE NAME&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;p&gt;And to &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/node_demote/&#34;&gt;demote&lt;/a&gt; a node, run this command:&lt;/p&gt;



  &lt;div class=&#34;collapsable-code&#34;&gt;
    &lt;input id=&#34;2&#34; type=&#34;checkbox&#34;  /&gt;
    &lt;label for=&#34;2&#34;&gt;
      &lt;span class=&#34;collapsable-code__language&#34;&gt;bash&lt;/span&gt;
      
      &lt;span class=&#34;collapsable-code__toggle&#34; data-label-expand=&#34;Show&#34; data-label-collapse=&#34;Hide&#34;&gt;&lt;/span&gt;
    &lt;/label&gt;
    &lt;pre class=&#34;language-bash&#34; &gt;&lt;code&gt;
$ docker node demote &amp;lt;NODE NAME&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/em&gt;: By default, all manager nodes are also worker nodes. Assuming you
have a cluster that has more than one node, you can prevent any one manager node
from taking on worker node responsibilities by moving it&amp;rsquo;s availability status
to &lt;code&gt;Drain&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;deployment-strategies&#34;&gt;Deployment Strategies&lt;/h1&gt;
&lt;p&gt;Okay, so we&amp;rsquo;ve nailed down the roles that nodes can play within a swarm, but you
may be wondering:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How do I choose which role(s) to assign to a node?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It&amp;rsquo;s a great question, and one that can have pretty large impact.&lt;/p&gt;
&lt;h2 id=&#34;to-manage-or-not-to-manage&#34;&gt;To Manage or Not to Manage&lt;/h2&gt;
&lt;p&gt;Just like any business, having too many or too little managers can be problematic.
When it comes to provisioning managers in a Docker Swarm, you want to strike the
right balance of &lt;strong&gt;resiliency&lt;/strong&gt; and &lt;strong&gt;performance&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s touch first on resiliency.&lt;/p&gt;
&lt;h3 id=&#34;resiliency&#34;&gt;Resiliency&lt;/h3&gt;
&lt;p&gt;One of the primary reasons why we are using an orchestration engine like Docker
Swarm is so that we can have a degree of fault tolerance. If any particular
node in the swarm decides to take an &amp;ldquo;unnannounced vacation&amp;rdquo;, we should be able
to schedule whatever tasks (containers that comprise a service) to a different,
active node.&lt;/p&gt;
&lt;p&gt;We have to be particularly strategic to provide this fault tolerance when it comes
to managers. After all, they are responsible for taking on some pretty important
and necessary tasks. In order to best understand how many managers we should
deploy, we should quickly touch on the algorithm Docker Swarm uses to ensure
consistent state.&lt;/p&gt;
&lt;h4 id=&#34;raft-consensus-algorithm&#34;&gt;Raft Consensus Algorithm&lt;/h4&gt;
&lt;p&gt;Sounds fancy right?&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;http://thesecretlivesofdata.com/raft/&#34;&gt;Raft Consensus Algorithm&lt;/a&gt; is essentially an algorithm that
Docker Swarm uses to make sure each manager in the cluster is storing the same
consistent state. The most important thing to note in the context of this discussion
is that manager nodes need to agree on what the state is, and that &amp;ldquo;agreement&amp;rdquo;
is achieved as a function of how many nodes share the same information. If the
majority, also referred to as a &amp;ldquo;quorum&amp;rdquo;, is achieved when new state is proposed,
then it will be distributed to all managers.&lt;/p&gt;
&lt;p&gt;Approaching this mathematically, we can essentially use the following simple
equations to determine achievable fault tolerance and quorum:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;given:
  N = the number of manager nodes in the cluster.

then:
  number of manager nodes that can be down = (N-1)/2
  number of manager nodes to achieve quorum = (N/2)+1
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;EXAMPLE:&lt;/em&gt;&lt;/strong&gt; Assuming we have &lt;code&gt;3&lt;/code&gt; manager nodes (&lt;code&gt;N = 3&lt;/code&gt;) in a cluster of &lt;code&gt;5&lt;/code&gt;
total nodes, we would be able to support &lt;code&gt;1&lt;/code&gt; manager node being down at any
moment in time (&lt;code&gt;(3-1)/2 = 1&lt;/code&gt;). The number of manager nodes to reach quorum
would be &lt;code&gt;2&lt;/code&gt; (&lt;code&gt;(3/2)+1 = 2&lt;/code&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ultimately, the number of managers you deploy in your cluster depends somewhat
on the total number of nodes in your cluster. It is recommended you have at least
&lt;code&gt;3&lt;/code&gt; manager nodes, as such a configuration allows for one manager node to be down.&lt;/p&gt;
&lt;h3 id=&#34;performance&#34;&gt;Performance&lt;/h3&gt;
&lt;p&gt;As with much in software design, the resiliency comes at a cost. Since one element
of increasing the resiliency involves introducing redundency, more work is required
to spread information as we introduce more managers. Adding more manager nodes,
means more managers are needed to meet quorum.&lt;/p&gt;
&lt;p&gt;When it comes to Docker Swarm, it&amp;rsquo;s generally &lt;a href=&#34;https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/#manager-nodes&#34;&gt;not recommended to have any more
than &lt;code&gt;7&lt;/code&gt; manager nodes&lt;/a&gt;. Such a configuration would allow &lt;code&gt;3&lt;/code&gt;
managers to be simultaneously down at any moment and require &lt;code&gt;4&lt;/code&gt; nodes to reach
quorum.&lt;/p&gt;
&lt;h3 id=&#34;unreachable-quorum&#34;&gt;Unreachable Quorum&lt;/h3&gt;
&lt;p&gt;In the event that the number of manager nodes simultaneously down exceeds the
allowable fault tolerance, the state of the cluster is not allowed to change.
New tasks cannot be scheduled, and the existing tasks cannot be rebalanced to
other nodes if required. The following error will be returned when a management
operation is attempted:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Error response from daemon: rpc error: code = 4 desc = context deadline exceeded
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The ideal way to recover here is to get manager nodes back online. If for some
reason the managers can&amp;rsquo;t be brought back online, a new cluster will need to
be provisioned. This can be performed using the following command:&lt;/p&gt;



  &lt;div class=&#34;collapsable-code&#34;&gt;
    &lt;input id=&#34;1&#34; type=&#34;checkbox&#34;  /&gt;
    &lt;label for=&#34;1&#34;&gt;
      &lt;span class=&#34;collapsable-code__language&#34;&gt;bash&lt;/span&gt;
      
      &lt;span class=&#34;collapsable-code__toggle&#34; data-label-expand=&#34;Show&#34; data-label-collapse=&#34;Hide&#34;&gt;&lt;/span&gt;
    &lt;/label&gt;
    &lt;pre class=&#34;language-bash&#34; &gt;&lt;code&gt;
$ docker swarm init --force-new-cluster --advertise-addr &amp;lt;IP&amp;gt;:2377
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;p&gt;Make sure to replace &lt;code&gt;&amp;lt;IP&amp;gt;&lt;/code&gt; with the IP address or DNS resolvable name of the
host you desire to be the initial manager of this new cluster.&lt;/p&gt;
&lt;h4 id=&#34;workers-get-shit-done&#34;&gt;Workers Get Shit Done&lt;/h4&gt;
&lt;p&gt;Compared to manager nodes, worker nodes are far simpler. Since they are
designated for executing the tasks for the swarm, the main deployment concerns
are simply ensuring that there are enough workers to balance the load.&lt;/p&gt;
&lt;p&gt;To join an existing swarm cluster as a worker node, run the following commands
to retrieve the worker join token:&lt;/p&gt;



  &lt;div class=&#34;collapsable-code&#34;&gt;
    &lt;input id=&#34;3&#34; type=&#34;checkbox&#34;  /&gt;
    &lt;label for=&#34;3&#34;&gt;
      &lt;span class=&#34;collapsable-code__language&#34;&gt;bash&lt;/span&gt;
      
      &lt;span class=&#34;collapsable-code__toggle&#34; data-label-expand=&#34;Show&#34; data-label-collapse=&#34;Hide&#34;&gt;&lt;/span&gt;
    &lt;/label&gt;
    &lt;pre class=&#34;language-bash&#34; &gt;&lt;code&gt;
$ docker swarm join-token worker
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;p&gt;Assuming the above command provided this output:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;docker swarm join \
  --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
  192.168.99.100:2377
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The final step would be to run that command:&lt;/p&gt;



  &lt;div class=&#34;collapsable-code&#34;&gt;
    &lt;input id=&#34;4&#34; type=&#34;checkbox&#34;  /&gt;
    &lt;label for=&#34;4&#34;&gt;
      &lt;span class=&#34;collapsable-code__language&#34;&gt;bash&lt;/span&gt;
      
      &lt;span class=&#34;collapsable-code__toggle&#34; data-label-expand=&#34;Show&#34; data-label-collapse=&#34;Hide&#34;&gt;&lt;/span&gt;
    &lt;/label&gt;
    &lt;pre class=&#34;language-bash&#34; &gt;&lt;code&gt;
$ docker swarm join \
  --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
  192.168.99.100:2377
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/em&gt;: When adding workers to accommodate for expected or current
workloads, make sure to take the various resource related requirements that
may be specified for a particular service. Remember that workers that
don&amp;rsquo;t meet those specified requirements will not be scheduled to execute
those tasks.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
    </item>
    
  </channel>
</rss>
